{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac440ed",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformer (TFT) — Cuaderno Comentado\n",
    "\n",
    "Este cuaderno ofrece una implementación **claramente documentada** del *Temporal Fusion Transformer* para pronóstico de series temporales. Además de las explicaciones en *Markdown*, los bloques de código incluyen comentarios y *docstrings* para guiar al lector a través de la lógica y los componentes de cada módulo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0261f",
   "metadata": {},
   "source": [
    "## 0 · Configuración y dependencias\n",
    "Instalación de librerías necesarias. Si ya las tienes, esta celda puede omitirse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-forecasting==1.0.0 pytorch-lightning==2.2.0 optuna==3.6.0 wandb --quiet\n",
    "# Nota: descomenta la línea anterior si las dependencias no están instaladas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca981e",
   "metadata": {},
   "source": [
    "### 0.1 Importaciones y utilidades\n",
    "Incluimos una función `set_seed` con docstring para fijar la aleatoriedad de forma reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"Fija las semillas de NumPy, random, PyTorch y PyTorch‑Lightning.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int, optional\n",
    "        Valor de la semilla. Por defecto 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    pl.seed_everything(seed, workers=True)\n",
    "\n",
    "# Establecemos la semilla global\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Configuraciones de rendimiento para GPU (si está disponible)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True  # Optimizaciones para tamaños de batch constantes\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# Compatibilidad con torch.compile (PyTorch ≥ 2)\n",
    "_USE_COMPILE = hasattr(torch, 'compile')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313290c",
   "metadata": {},
   "source": [
    "## 1 · Carga y preprocesamiento de datos\n",
    "En esta sección leemos el CSV, mostramos sus primeras filas y optimizamos los tipos para reducir consumo de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_optimize(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Carga un CSV y optimiza los tipos de dato para ahorrar memoria.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Ruta al archivo CSV.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame optimizado y listo para usar.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Downcast de tipos numéricos y conversión de objetos a categorías\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        if dtype == 'object':\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif dtype == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        elif dtype == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "\n",
    "    # Conversión explícita a float32 (PyTorch trabaja en 32‑bit)\n",
    "    float_cols = df.select_dtypes(include=['float32', 'float64']).columns\n",
    "    df[float_cols] = df[float_cols].astype('float32')\n",
    "    return df\n",
    "\n",
    "# Carga del dataset\n",
    "df = load_and_optimize('data.csv')  # ← ajusta la ruta\n",
    "\n",
    "# Vista rápida\n",
    "display(df.head())\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc67b0",
   "metadata": {},
   "source": [
    "## 2 · Preparación del `TimeSeriesDataSet`\n",
    "Agrupamos la creación de los objetos de datos en una función para encapsular la lógica y añadir un docstring claro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(\n",
    "    df: pd.DataFrame,\n",
    "    encoder_length: int = 24,\n",
    "    prediction_length: int = 6,\n",
    "):\n",
    "    \"\"\"Crea `TimeSeriesDataSet` de entrenamiento y validación.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Conjunto de datos con columnas `series_id`, `time_idx` y `target`.\n",
    "    encoder_length : int, optional\n",
    "        Longitud de ventana para el codificador (pasos de contexto).\n",
    "    prediction_length : int, optional\n",
    "        Horizonte de predicción.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[TimeSeriesDataSet, TimeSeriesDataSet]\n",
    "        Conjuntos de entrenamiento y validación.\n",
    "    \"\"\"\n",
    "    cutoff = df['time_idx'].max() - prediction_length\n",
    "    training = TimeSeriesDataSet(\n",
    "        df[df.time_idx <= cutoff],\n",
    "        time_idx='time_idx',\n",
    "        target='target',\n",
    "        group_ids=['series_id'],\n",
    "        max_encoder_length=encoder_length,\n",
    "        max_prediction_length=prediction_length,\n",
    "        time_varying_known_reals=['time_idx'],\n",
    "        time_varying_unknown_reals=['target'],\n",
    "    )\n",
    "\n",
    "    validation = TimeSeriesDataSet.from_dataset(\n",
    "        training, df, predict=True, stop_randomization=True\n",
    "    )\n",
    "    return training, validation\n",
    "\n",
    "# Preparamos los datasets\n",
    "training_ds, validation_ds = prepare_datasets(df)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 128\n",
    "train_dataloader = training_ds.to_dataloader(batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True, persistent_workers=True)\n",
    "val_dataloader   = validation_ds.to_dataloader(batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973fc182",
   "metadata": {},
   "source": [
    "## 3 · Construcción del modelo TFT\n",
    "Definimos una función `build_tft_model` con parámetros configurables y docstring detallado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2c450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tft_model(dataset: TimeSeriesDataSet,\n",
    "                    hidden_size: int = 128,\n",
    "                    attention_heads: int = 4,\n",
    "                    dropout: float = 0.1,\n",
    "                    learning_rate: float = 1e-3) -> TemporalFusionTransformer:\n",
    "    \"\"\"Crea una instancia de `TemporalFusionTransformer`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : TimeSeriesDataSet\n",
    "        Conjunto de datos de referencia (para extraer metadatos).\n",
    "    hidden_size : int, optional\n",
    "        Dimensión de las capas LSTM y de atención.\n",
    "    attention_heads : int, optional\n",
    "        Número de cabezas de atención multi‑cabeza.\n",
    "    dropout : float, optional\n",
    "        Probabilidad de *dropout* para regularización.\n",
    "    learning_rate : float, optional\n",
    "        Tasa de aprendizaje inicial.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TemporalFusionTransformer\n",
    "        Modelo configurado.\n",
    "    \"\"\"\n",
    "    loss = QuantileLoss()\n",
    "    model = TemporalFusionTransformer(\n",
    "        input_size=len(dataset.reals),\n",
    "        output_size=loss.output_size,\n",
    "        hidden_size=hidden_size,\n",
    "        attention_head_size=attention_heads,\n",
    "        dropout=dropout,\n",
    "        hidden_continuous_size=64,\n",
    "        learning_rate=learning_rate,\n",
    "        loss=loss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "    )\n",
    "    if _USE_COMPILE:\n",
    "        model = torch.compile(model)\n",
    "    return model\n",
    "\n",
    "# Creamos el modelo\n",
    "tft = build_tft_model(training_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87a921",
   "metadata": {},
   "source": [
    "## 4 · Entrenamiento del modelo\n",
    "Se configura `pl.Trainer` y se ajusta automáticamente el learning rate mediante `lr_find`. Los pasos clave están anotados con comentarios para facilitar el seguimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b669a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    precision='16-mixed' if torch.cuda.is_available() else 32,\n",
    "    gradient_clip_val=0.5,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=4, mode='min'),\n",
    "        ModelCheckpoint(monitor='val_loss', mode='min', filename='tft-{epoch:02d}-{val_loss:.4f}'),\n",
    "        LearningRateMonitor(logging_interval='epoch'),\n",
    "    ],\n",
    "    log_every_n_steps=50,\n",
    ")\n",
    "\n",
    "# Encontrar learning rate óptimo\n",
    "lr_finder = trainer.tuner.lr_find(tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "tft.hparams.learning_rate = lr_finder.suggestion()\n",
    "print(f'LR óptimo sugerido: {tft.hparams.learning_rate:.3e}')\n",
    "\n",
    "# Entrenamiento final\n",
    "trainer.fit(tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "# Resumen de métricas\n",
    "for k, v in trainer.callback_metrics.items():\n",
    "    try:\n",
    "        print(f'{k}: {v:.4f}')\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b834ba",
   "metadata": {},
   "source": [
    "## 5 · Evaluación e interpretación\n",
    "Generamos predicciones en validación y graficamos los resultados para el primer índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = TemporalFusionTransformer.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "raw_predictions, x = best_model.predict(val_dataloader, mode='raw', return_x=True)\n",
    "best_model.plot_prediction(x, raw_predictions, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7119d3b",
   "metadata": {},
   "source": [
    "## 6 · Búsqueda de hiperparámetros con Optuna\n",
    "La función `objective` se documenta para explicar qué parámetros se ajustan y cómo se devuelve la métrica de optimización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"Función objetivo para Optuna.\n",
    "\n",
    "    Ajusta `hidden_size`, `attention_head_size`, `dropout` y `learning_rate`,\n",
    "    entrenando un TFT reducido.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial : optuna.Trial\n",
    "        Objeto trial que sugiere combinaciones hiperparámetricas.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Pérdida de validación (a minimizar).\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 64, 256, step=32),\n",
    "        'attention_head_size': trial.suggest_categorical('attention_head_size', [2, 4, 8]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.1, 0.4, step=0.05),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 5e-3, log=True),\n",
    "    }\n",
    "    model = build_tft_model(training_ds, **params)\n",
    "    tuner = pl.Trainer(max_epochs=10, accelerator='auto', devices='auto', precision='16-mixed' if torch.cuda.is_available() else 32, enable_progress_bar=False)\n",
    "    tuner.fit(model, train_dataloader, val_dataloader)\n",
    "    return tuner.callback_metrics['val_loss'].item()\n",
    "\n",
    "# Descomenta para ejecutar (toma tiempo)\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=25)\n",
    "# print('Mejores hiperparámetros:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b178d",
   "metadata": {},
   "source": [
    "## 7 · Exportación del modelo\n",
    "Exportamos a TorchScript para despliegue en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted = torch.jit.script(best_model.to_torchscript(method='script'))\n",
    "scripted.save('tft_scripted.pt')\n",
    "print('Modelo exportado → tft_scripted.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c573d85",
   "metadata": {},
   "source": [
    "## 8 · Perfilado y monitorización\n",
    "Guardamos una traza en formato *Chrome Trace* para inspección detallada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.profiler as profiler\n",
    "\n",
    "with profiler.profile(activities=[profiler.ProfilerActivity.CPU, profiler.ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    best_model.forward(x[0])\n",
    "\n",
    "prof.export_chrome_trace('trace.json')\n",
    "print('Traza guardada en trace.json. Ábrela en Chrome → about://tracing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f854f7e",
   "metadata": {},
   "source": [
    "---\n",
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
